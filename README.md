[![Typing SVG](https://readme-typing-svg.herokuapp.com?color=%23AB3FF7&lines=Sign+Language+To+Speech+Translator)](https://git.io/typing-svg)

<img width="295" alt="image" src="https://user-images.githubusercontent.com/60210475/152521069-68b42841-db40-47e0-a216-174807706c90.png">
<img width="357" alt="image" src="https://user-images.githubusercontent.com/60210475/152521195-8de9e7bf-da83-4a39-a8bb-c71d7ccb5bb3.png">

 A deep learning project which focused to solve the problem of the people with hearing and speech disabilities.
 
• Existing systems worked on American Sign language ,this project focused on the Indian Sign Language gestures.

• Gloves were used for image capturing through which the gestures were recognized, followed by conversion them to sentences.

• CNN was used to train the model which resulted in an accuracy of 94%.

• The features detected through this model were visualized through matplotlib and Keras in a feature map.

• The sentences formed were converted to speech using GTTS (Google Text to Speech)


