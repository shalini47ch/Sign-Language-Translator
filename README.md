[![Typing SVG](https://readme-typing-svg.herokuapp.com?color=%23AB3FF7&lines=Sign+Language+To+Speech+Translator)](https://git.io/typing-svg)

<img width="295" alt="image" src="https://user-images.githubusercontent.com/60210475/152521069-68b42841-db40-47e0-a216-174807706c90.png">
<img width="357" alt="image" src="https://user-images.githubusercontent.com/60210475/152521195-8de9e7bf-da83-4a39-a8bb-c71d7ccb5bb3.png">

<img width="427" alt="Screenshot 2022-03-30 230014" src="https://user-images.githubusercontent.com/60210475/160895994-97e35d52-5f81-4830-8d49-259b53abe134.png">


 A deep learning project which focused to solve the problem of the people with hearing and speech disabilities.
 
• Existing systems worked on American Sign language ,this project focused on the Indian Sign Language gestures.

• Gloves were used for image capturing through which the gestures were recognized, followed by converting them to sentences.

• CNN was used to train the model which resulted in an accuracy of 94%.

• The features detected through this model were visualized through matplotlib and Keras in a feature map.

• The sentences formed were converted to speech using GTTS (Google Text to Speech)

<img width="267" alt="image" src="https://github.com/shalini47ch/Sign-Language-Translator/assets/60210475/9e925822-1cee-4ba7-9384-0fd88be6c275">
<img width="268" alt="image" src="https://github.com/shalini47ch/Sign-Language-Translator/assets/60210475/7ca98329-e27b-4125-acdc-1d37603f9848">

